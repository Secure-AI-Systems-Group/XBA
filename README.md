# XBA
This repository implements XBA, a deep learning tool for generating platform-agnostic binary code embeddings. XBA applies graph convolutional network on the graph representation of binary which we call Binary Disassembly Graph (BDG). XBA can learn semantic matchings of binary code compiled for different platfroms that are not included in the training dataset. It outperformed prior works in aligning binary code blocks for different platforms, that shows the embeddings generated by XBA can be used in the cross binary analysis.

![overview](./gcnoverview.jpg)

## Setup

### Structure
The working directory should be structured as follows.

    .
    ├── README
    ├── Pipfile                 # Manages a Python virtualenv.
    ├── Pipfile.lock            # Manages a Python virtualenv (Do not touch).
    ├── baseline.py             # Calculate the hit score of baselines (BoW, DeepBinDiff, InnerEye).
    ├── get_rank.py             # Calculate individual rankings of binary code block pairs.
    ├── layers.py               # Define the graph convolution layer.
    ├── metrics.py              # Define the margin-based hinge loss function and hit score calculation.
    ├── models.py               # Define a tensorflow implementation of XBA.
    ├── train_general.py        # Train the model on the whole training dataset across binaries
    ├── train.py                # Train the model.
    ├── utils.py                # Define utility functions.
    ├── xba.py                  # This file defines XBA class that wraps tensorflow specific code for data load, training, validation, test.
    ├── script                  # Includes script files that can reproduce experiments presented in the paper.
    │   ├── table{x}-..         # Reproduce results of the table {x}.
    │   └── test-run.sh         # Test run XBA with 10 epochs for each dataset.
    ├── result                  # Default directory that the hit scores are stored.
    │   └── ...                 #
    ├── history                 # Default directory that the history of training is stored.
    │   └── ...                 #
    ├── data_processing         # 
    │   ├── build_vocab.py      # Build a vocabulary for generating BoW features.
    │   └── split_seed_alignments.py      # Split the training data and test data so that experiment results are deterministic.
    ├── data                    # Graph data for each binary.
    │   ├── curl                # 
    │   │   ├── seed_alignments                # Default directory for split_seed_alignments.py that randomly split alignment.csv into the test data and training data. 
    │   │   ├── alignment.csv                # Pair-wise-labeled data
    │   │   ├── deepbindiff_embeddings.pt                # DeepBinDiff embeddings for binary code blocks.
    │   │   ├── disasm_innereye.json                # Binary code blocks used to generate InnerEye embeddings.
    │   │   ├── disasm.json                # Binary code blocks used to generate DeepBinDiff, BoW, and XBA.
    │   │   ├── extfuncs.json                # 
    │   │   ├── gcn1-relation.csv                # Relation list of graph generated from a binary for Linux
    │   │   ├── gcn2-relation.csv                # Relation list of graph generated from a binary for Windows
    │   │   ├── innereye_embeddings_{curl_openssl_httpd_sqlite3_libcrypto}.pt                # Innereye embedding generated by training on labeled pairs from curl, openssl, httpd, sqlite3, and libcrypto.
    │   │   ├── innereye.csv                # alignment.csv for training InnerEye (This is not used in XBA)
    │   │   ├── mapping.csv                #
    │   │   └── subgraph.pth                #
    │   ├── httpd               # 
    │   ├── libc                # Graph 1 is generated from a binary for x86 and graph 2 is generated from a binary for arm.
    │   ├── libcrypto           # 
    │   ├── libcrypto-xarch     # Graph 1 is generated from a binary for x86 and graph 2 is generated from a binary for arm.
    │   ├── openssl             # 
    │   └── sqlite3             # 
    ├── vocabulary              # Default directory for storing generated vocabulary by build_vocab.py.
    └── saved_model             # Default directory for storing model parameters.  

### Install
Prerequisites
```shellsciprt
$ pip3 install pipenv
```
#### Use pipenv shell

Install dependencies
```shellscript
$ pipenv install
```

Activate pipenv shell
```shellscript
$ pipenv shell
```

#### Use your own Python virtual environment

Extract requirements.txt
```shellscript
$ pipenv lock -r > requirements.txt
```

Install dependencies
```shellscript
$ pip install -r requirements.txt
```

### Dataset




## Getting Started

## Detailed Description

### Training

### Exaustive Comparisons

### Indivisual Comparisons



### data processing

## How to run


Training GCN model on {target} based on {embedding_type} with 10/20/30/40/50% seed alignments and store models in `saved_model`. Results will be stored in `result` directory in root directory.
```shellscript
$ pipenv run -- python train.py --target {target} --embedding_type {embedding_type} --seed {1|2|3|4|5} --log warning
```

Run baseline (matching only with BB attribute features)
```shellscript
$ pipenv run -- python baseline.py --target{target} --embedding_type {embedding_type} --log warning --seed {1|2|3|4|5}
```

Calculate the ranking of indivisual block pairs which did not appeared in seed alignment using fully trained (100% seed alignments) gcn model.
```shellscript
$ pipenv run -- python get_rank.py --target {target} --embedding_type {embedding_type} --log warning --bb_id1="{block id list}" --bb_id2="{block id list}"
```

Split alignments data into training and test data with ratio of 10/20/30/40/50%
```shellscript
$ python split_seed_alignments.py --target libcrypto
```

## Citation
```
TBA
```